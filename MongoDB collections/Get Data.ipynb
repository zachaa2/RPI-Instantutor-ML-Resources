{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86963428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crse</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>subj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARCH-1200</th>\n",
       "      <td>1200</td>\n",
       "      <td>Two-week introduction to architecture for risi...</td>\n",
       "      <td>Beginners Architecture Career Discovery Program</td>\n",
       "      <td>ARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH-1210</th>\n",
       "      <td>1210</td>\n",
       "      <td>Similar structure as the Beginners program. Th...</td>\n",
       "      <td>Advanced Architecture Career Discovery Program</td>\n",
       "      <td>ARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH-2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>This course will examine the spectrum of archi...</td>\n",
       "      <td>The Ethos of Architecture</td>\n",
       "      <td>ARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH-2160</th>\n",
       "      <td>2160</td>\n",
       "      <td>This course continues the inquiry begun in ARC...</td>\n",
       "      <td>Architectural Media</td>\n",
       "      <td>ARCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH-2330</th>\n",
       "      <td>2330</td>\n",
       "      <td>Introduction to Structures introduces the stud...</td>\n",
       "      <td>Structures 1</td>\n",
       "      <td>ARCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           crse                                        description  \\\n",
       "ARCH-1200  1200  Two-week introduction to architecture for risi...   \n",
       "ARCH-1210  1210  Similar structure as the Beginners program. Th...   \n",
       "ARCH-2150  2150  This course will examine the spectrum of archi...   \n",
       "ARCH-2160  2160  This course continues the inquiry begun in ARC...   \n",
       "ARCH-2330  2330  Introduction to Structures introduces the stud...   \n",
       "\n",
       "                                                      name  subj  \n",
       "ARCH-1200  Beginners Architecture Career Discovery Program  ARCH  \n",
       "ARCH-1210   Advanced Architecture Career Discovery Program  ARCH  \n",
       "ARCH-2150                        The Ethos of Architecture  ARCH  \n",
       "ARCH-2160                              Architectural Media  ARCH  \n",
       "ARCH-2330                                     Structures 1  ARCH  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_json(\"catalog.json\")\n",
    "#df.head()\n",
    "tdf = df.transpose()\n",
    "tdf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8050ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "--------------------- DATA CLEANING -----------------------\n",
    "\n",
    "'''\n",
    "import contractions # expands contractions (ex: I'll => I will)\n",
    "'''\n",
    "FUNCTIONS\n",
    "'''\n",
    "\n",
    "def contraction_expand(df):\n",
    "    return contractions.fix(df)\n",
    "\n",
    "def lowercase_text(df):\n",
    "    return df.lower()\n",
    "\n",
    "def string_text(df):\n",
    "    return str(df)\n",
    "\n",
    "def remove_user(df):\n",
    "    return re.sub('@[^\\s]+','', df)\n",
    "\n",
    "def remove_link(df):\n",
    "    return re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , df)\n",
    "\n",
    "def remove_email(df):\n",
    "    return re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", df)\n",
    "\n",
    "def remove_time(df):\n",
    "    df = re.sub(r'\\d+:\\d{2}', \"\", df)\n",
    "    df = re.sub(r' am.', \"\", df)\n",
    "    return re.sub(r' pm.', \"\", df)\n",
    "\n",
    "def remove_symbols(df):\n",
    "    df = re.sub(r'\\\\+', \" \", df)\n",
    "    df = re.sub(r'\\,+', \" \", df)\n",
    "    return re.sub(r'\\\"+', \" \", df)\n",
    "\n",
    "def remove_short_words(df):\n",
    "    df = re.sub(r'\\b\\w{1,3}\\b', \"\", df)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def strip_text(df):\n",
    "    return df.strip()\n",
    "\n",
    "\n",
    "'''\n",
    "DRIVER FUNCTION\n",
    "'''\n",
    "\n",
    "def clean_data(df):\n",
    "    df = string_text(df)\n",
    "    df = contraction_expand(df)\n",
    "    df = lowercase_text(df)\n",
    "    df = remove_email(df)\n",
    "    df = remove_link(df)\n",
    "    df = remove_time(df)\n",
    "    df = remove_user(df)\n",
    "    df = strip_text(df)\n",
    "    df = remove_symbols(df)\n",
    "    return df\n",
    "\n",
    "# Seperate Function to handle removing special characters\n",
    "def remove_special_chars(df):\n",
    "    df = re.sub(r'[^\\w]+', \" \", df)\n",
    "    df = ' '.join(df.split())\n",
    "    return df\n",
    "\n",
    "def remove_digits(df):\n",
    "    df = re.sub(r'\\d+', '', df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800ec03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['description'] = tdf['description'].apply(clean_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea26d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python module based of Numpy and Scipy for NLP preprocessing\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "# handy function for removing stopwords\n",
    "# simply have to apply this function to the dataset\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0597a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['description'] = tdf['description'].apply(remove_stopwords)\n",
    "tdf['description'] = tdf['description'].apply(remove_digits)\n",
    "tdf['description'] = tdf['description'].apply(remove_special_chars)\n",
    "tdf['description'] = tdf['description'].apply(remove_short_words)\n",
    "\n",
    "\n",
    "'''\n",
    "# write cleaned df to json\n",
    "clean = tdf.transpose()\n",
    "clean.to_json(\"out.json\", orient='columns')\n",
    "clean.head()\n",
    "# write descriptions to json\n",
    "tdf['description'].to_json(\"clean_desc.json\", orient='columns')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "686a0fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07031246299022464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "req = \"Recursion, Binary Trees, Hash Tables, Multiple Inheritance & Exception...\"\n",
    "\n",
    "# get TFIDF vectorizer b/w request and each course description\n",
    "# use cosine similarity to get pairwise similarities b/w all samples in the data\n",
    "# add to list, and get the max cosine similarity\n",
    "\n",
    "vals = {}\n",
    "for i in range(len(tdf['description'])):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    data = [req, tdf['description'][i]]\n",
    "    mat = tfidf.fit_transform(data)\n",
    "    sim_mat = cosine_similarity(mat)\n",
    "    vals.append(sim_mat[0][1])\n",
    "\n",
    "print(max(vals))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fc51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
